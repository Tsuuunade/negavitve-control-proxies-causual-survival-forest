{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9f73e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Add parent directory to Python path\n",
    "import sys\n",
    "from pathlib import Path\n",
    "parent_dir = Path.cwd().parent\n",
    "if str(parent_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(parent_dir))\n",
    "\n",
    "from nc_csf.models import NCCausalForestDML, NCCausalForestDMLOracle, BaselineCausalForestDML\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be56a76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset: (5735, 63)\n",
      "Columns: ['Unnamed: 0', 'cat1', 'cat2', 'ca', 'sadmdte', 'dschdte', 'dthdte', 'lstctdte', 'death', 'cardiohx', 'chfhx', 'dementhx', 'psychhx', 'chrpulhx', 'renalhx', 'liverhx', 'gibledhx', 'malighx', 'immunhx', 'transhx', 'amihx', 'age', 'sex', 'edu', 'surv2md1', 'das2d3pc', 't3d30', 'dth30', 'aps1', 'scoma1', 'meanbp1', 'wblc1', 'hrt1', 'resp1', 'temp1', 'pafi1', 'alb1', 'hema1', 'bili1', 'crea1', 'sod1', 'pot1', 'paco21', 'ph1', 'swang1', 'wtkilo1', 'dnr1', 'ninsclas', 'resp', 'card', 'neuro', 'gastr', 'renal', 'meta', 'hema', 'seps', 'trauma', 'ortho', 'adld3p', 'urin1', 'race', 'income', 'ptid']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>ca</th>\n",
       "      <th>sadmdte</th>\n",
       "      <th>dschdte</th>\n",
       "      <th>dthdte</th>\n",
       "      <th>lstctdte</th>\n",
       "      <th>death</th>\n",
       "      <th>cardiohx</th>\n",
       "      <th>...</th>\n",
       "      <th>meta</th>\n",
       "      <th>hema</th>\n",
       "      <th>seps</th>\n",
       "      <th>trauma</th>\n",
       "      <th>ortho</th>\n",
       "      <th>adld3p</th>\n",
       "      <th>urin1</th>\n",
       "      <th>race</th>\n",
       "      <th>income</th>\n",
       "      <th>ptid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>COPD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>11142</td>\n",
       "      <td>11151.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11382</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>white</td>\n",
       "      <td>Under $11k</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>MOSF w/Sepsis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>11799</td>\n",
       "      <td>11844.0</td>\n",
       "      <td>11844.0</td>\n",
       "      <td>11844</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1437.0</td>\n",
       "      <td>white</td>\n",
       "      <td>Under $11k</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>MOSF w/Malignancy</td>\n",
       "      <td>MOSF w/Sepsis</td>\n",
       "      <td>Yes</td>\n",
       "      <td>12083</td>\n",
       "      <td>12143.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12400</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>599.0</td>\n",
       "      <td>white</td>\n",
       "      <td>$25-$50k</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ARF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>11146</td>\n",
       "      <td>11183.0</td>\n",
       "      <td>11183.0</td>\n",
       "      <td>11182</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>white</td>\n",
       "      <td>$11-$25k</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>MOSF w/Sepsis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>12035</td>\n",
       "      <td>12037.0</td>\n",
       "      <td>12037.0</td>\n",
       "      <td>12036</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.0</td>\n",
       "      <td>white</td>\n",
       "      <td>Under $11k</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0               cat1           cat2   ca  sadmdte  dschdte  \\\n",
       "0           1               COPD            NaN  Yes    11142  11151.0   \n",
       "1           2      MOSF w/Sepsis            NaN   No    11799  11844.0   \n",
       "2           3  MOSF w/Malignancy  MOSF w/Sepsis  Yes    12083  12143.0   \n",
       "3           4                ARF            NaN   No    11146  11183.0   \n",
       "4           5      MOSF w/Sepsis            NaN   No    12035  12037.0   \n",
       "\n",
       "    dthdte  lstctdte death  cardiohx  ...  meta  hema  seps  trauma  ortho  \\\n",
       "0      NaN     11382    No         0  ...    No    No    No      No     No   \n",
       "1  11844.0     11844   Yes         1  ...    No    No   Yes      No     No   \n",
       "2      NaN     12400    No         0  ...    No    No    No      No     No   \n",
       "3  11183.0     11182   Yes         0  ...    No    No    No      No     No   \n",
       "4  12037.0     12036   Yes         0  ...    No    No    No      No     No   \n",
       "\n",
       "   adld3p   urin1   race      income  ptid  \n",
       "0     0.0     NaN  white  Under $11k     5  \n",
       "1     NaN  1437.0  white  Under $11k     7  \n",
       "2     NaN   599.0  white    $25-$50k     9  \n",
       "3     NaN     NaN  white    $11-$25k    10  \n",
       "4     NaN    64.0  white  Under $11k    11  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('rhc.csv')\n",
    "\n",
    "print(f\"Shape of the dataset: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81aad49b",
   "metadata": {},
   "source": [
    "I found two papers online that uses RHC dataset. Their ways of choosing covariates X differs a bit, so I created two dataframes to run the test. Note that I didn't run the oracle model since we don't actually know the ground truth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf52e4bc",
   "metadata": {},
   "source": [
    "### Tchetgen Tchetgen, E. J., Ying, A., Cui, Y., Shi, X., and Miao, W. An introduction to proximal causal learning. arXiv preprint arXiv:2009.10982, 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a87c523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final X shape: (5735, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>A</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>race_black</th>\n",
       "      <th>pafi1</th>\n",
       "      <th>paco21</th>\n",
       "      <th>ph1</th>\n",
       "      <th>hema1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>70.25098</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68.00000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>7.359375</td>\n",
       "      <td>58.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>78.17896</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>218.31250</td>\n",
       "      <td>34.0</td>\n",
       "      <td>7.329102</td>\n",
       "      <td>32.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>46.09198</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>275.50000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.359375</td>\n",
       "      <td>21.097656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>75.33197</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>156.65625</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7.459961</td>\n",
       "      <td>26.296875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>67.90997</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>478.00000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.229492</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Y  A       age  sex  race_black      pafi1  paco21       ph1      hema1\n",
       "0  30  0  70.25098    0           0   68.00000    40.0  7.359375  58.000000\n",
       "1  30  1  78.17896    1           0  218.31250    34.0  7.329102  32.500000\n",
       "2  30  1  46.09198    1           0  275.50000    16.0  7.359375  21.097656\n",
       "3  30  0  75.33197    1           0  156.65625    30.0  7.459961  26.296875\n",
       "4   2  1  67.90997    0           0  478.00000    17.0  7.229492  24.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treatment A\n",
    "A_raw = df[\"swang1\"]\n",
    "if A_raw.dtype == \"O\":\n",
    "    A = (A_raw == \"RHC\").astype(int)\n",
    "else:\n",
    "    A = (A_raw.astype(float) > 0).astype(int)\n",
    "\n",
    "# Outcome Y\n",
    "Y = df[\"t3d30\"]\n",
    "\n",
    "# Covariates X\n",
    "X = pd.DataFrame({\n",
    "    \"age\": df[\"age\"],\n",
    "    \"sex\": df[\"sex\"],\n",
    "    \"race\": df[\"race\"]\n",
    "})\n",
    "\n",
    "if X[\"sex\"].dtype == \"O\":\n",
    "    X[\"sex\"] = (X[\"sex\"] == \"Female\").astype(int)\n",
    "\n",
    "if X[\"race\"].dtype == \"O\":\n",
    "    X[\"race_black\"] = (X[\"race\"] == \"black\").astype(int)\n",
    "    X = X.drop(columns=[\"race\"])\n",
    "\n",
    "# Proxies Z & W\n",
    "Z = df[[\"pafi1\", \"paco21\"]].copy() \n",
    "W = df[[\"ph1\", \"hema1\"]].copy()  \n",
    "\n",
    "analysis_cols = pd.concat(\n",
    "    [\n",
    "        Y.rename(\"Y\"),\n",
    "        A.rename(\"A\"),\n",
    "        X,\n",
    "        Z.rename(columns={\"pafi1\": \"pafi1\", \"paco21\": \"paco21\"}),\n",
    "        W.rename(columns={\"ph1\": \"ph1\", \"hema1\": \"hema1\"}),\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "analysis_df = analysis_cols.dropna().copy()\n",
    "\n",
    "# Overwrite with cleaned arrays\n",
    "Y = analysis_df[\"Y\"].values\n",
    "A = analysis_df[\"A\"].values.astype(int)\n",
    "X_colnames = [col for col in analysis_df.columns if col not in [\"Y\", \"A\", \"pafi1\", \"paco21\", \"ph1\", \"hema1\"]]\n",
    "X = analysis_df[X_colnames]\n",
    "Z = analysis_df[[\"pafi1\", \"paco21\"]]\n",
    "W = analysis_df[[\"ph1\", \"hema1\"]]\n",
    "\n",
    "print(f\"\\nFinal X shape: {X.shape}\")\n",
    "analysis_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3a7a37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 4014\n",
      "Test samples: 1721\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, A_train, A_test, Y_train, Y_test, Z_train, Z_test, W_train, W_test = train_test_split(\n",
    "    X.values, A, Y, Z.values, W.values, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e5df696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Baseline predictions - Mean: -1.8407, Std: 1.8258\n",
      "Baseline predictions - Min: -7.3242, Max: 1.8520\n"
     ]
    }
   ],
   "source": [
    "baseline = BaselineCausalForestDML(n_estimators=200, min_samples_leaf=20, random_state=42)\n",
    "baseline.fit_baseline(X_train, A_train, Y_train, verbose=True)\n",
    "pred_baseline = baseline.effect(X_test).ravel()\n",
    "\n",
    "print(f\"\\nBaseline predictions - Mean: {pred_baseline.mean():.4f}, Std: {pred_baseline.std():.4f}\")\n",
    "print(f\"Baseline predictions - Min: {pred_baseline.min():.4f}, Max: {pred_baseline.max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74f247ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NC-CSF predictions - Mean: -1.0050, Std: 1.9093\n",
      "NC-CSF predictions - Min: -6.8569, Max: 3.3692\n"
     ]
    }
   ],
   "source": [
    "nccsf = NCCausalForestDML(n_estimators=200, min_samples_leaf=20, cv=5, random_state=42)\n",
    "nccsf.fit(Y=Y_train, T=A_train, X=X_train, Z=Z_train, W=W_train)\n",
    "pred_nccsf = nccsf.effect(X_test).ravel()\n",
    "\n",
    "print(f\"\\nNC-CSF predictions - Mean: {pred_nccsf.mean():.4f}, Std: {pred_nccsf.std():.4f}\")\n",
    "print(f\"NC-CSF predictions - Min: {pred_nccsf.min():.4f}, Max: {pred_nccsf.max():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ebdb24",
   "metadata": {},
   "source": [
    "### Sverdrup, E., Cui, Y. Proximal Causal Learning of Conditional Average Treatment Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "327291ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final X shape: (5735, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>A</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cat1_coma</th>\n",
       "      <th>cat2_coma</th>\n",
       "      <th>dnr1</th>\n",
       "      <th>surv2md1</th>\n",
       "      <th>aps1</th>\n",
       "      <th>pafi1</th>\n",
       "      <th>paco21</th>\n",
       "      <th>ph1</th>\n",
       "      <th>hema1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>70.25098</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.640991</td>\n",
       "      <td>46</td>\n",
       "      <td>68.00000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>7.359375</td>\n",
       "      <td>58.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>78.17896</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.755000</td>\n",
       "      <td>50</td>\n",
       "      <td>218.31250</td>\n",
       "      <td>34.0</td>\n",
       "      <td>7.329102</td>\n",
       "      <td>32.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>46.09198</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.317000</td>\n",
       "      <td>82</td>\n",
       "      <td>275.50000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.359375</td>\n",
       "      <td>21.097656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>75.33197</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.440979</td>\n",
       "      <td>48</td>\n",
       "      <td>156.65625</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7.459961</td>\n",
       "      <td>26.296875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>67.90997</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.437000</td>\n",
       "      <td>72</td>\n",
       "      <td>478.00000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.229492</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Y  A       age  sex  cat1_coma  cat2_coma  dnr1  surv2md1  aps1  \\\n",
       "0  30  0  70.25098    0          0          0     0  0.640991    46   \n",
       "1  30  1  78.17896    1          0          0     0  0.755000    50   \n",
       "2  30  1  46.09198    1          0          0     0  0.317000    82   \n",
       "3  30  0  75.33197    1          0          0     0  0.440979    48   \n",
       "4   2  1  67.90997    0          0          0     1  0.437000    72   \n",
       "\n",
       "       pafi1  paco21       ph1      hema1  \n",
       "0   68.00000    40.0  7.359375  58.000000  \n",
       "1  218.31250    34.0  7.329102  32.500000  \n",
       "2  275.50000    16.0  7.359375  21.097656  \n",
       "3  156.65625    30.0  7.459961  26.296875  \n",
       "4  478.00000    17.0  7.229492  24.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treatment A\n",
    "A_raw = df[\"swang1\"]\n",
    "if A_raw.dtype == \"O\":\n",
    "    A = (A_raw == \"RHC\").astype(int)\n",
    "else:\n",
    "    A = (A_raw.astype(float) > 0).astype(int)\n",
    "\n",
    "# Outcome Y\n",
    "Y = df[\"t3d30\"]\n",
    "\n",
    "# Covariates X\n",
    "# Note we define cat1_coma and cat2_coma by ourselves since it doesn't exist in the original dataset\n",
    "# reference: https://search.r-project.org/CRAN/refmans/ATbounds/html/RHC.html\n",
    "X = pd.DataFrame({\n",
    "    \"age\": df[\"age\"],\n",
    "    \"sex\": df[\"sex\"],\n",
    "    \"cat1_coma\": df[\"cat1\"].apply(lambda x: 1 if x in [\"Coma\"] else 0),\n",
    "    \"cat2_coma\": df[\"cat2\"].apply(lambda x: 1 if x in [\"Coma\"] else 0),\n",
    "    \"dnr1\": df[\"dnr1\"],\n",
    "    \"surv2md1\": df[\"surv2md1\"],\n",
    "    \"aps1\": df[\"aps1\"],\n",
    "})\n",
    "\n",
    "if X[\"sex\"].dtype == \"O\":\n",
    "    X[\"sex\"] = (X[\"sex\"] == \"Female\").astype(int)\n",
    "\n",
    "if X[\"dnr1\"].dtype == \"O\":\n",
    "    X[\"dnr1\"] = X[\"dnr1\"].map({\"Yes\": 1, \"No\": 0}).fillna(0).astype(int)\n",
    "\n",
    "# Proxies Z & W\n",
    "Z = df[[\"pafi1\", \"paco21\"]].copy() \n",
    "W = df[[\"ph1\", \"hema1\"]].copy()  \n",
    "\n",
    "analysis_cols = pd.concat(\n",
    "    [\n",
    "        Y.rename(\"Y\"),\n",
    "        A.rename(\"A\"),\n",
    "        X,\n",
    "        Z.rename(columns={\"pafi1\": \"pafi1\", \"paco21\": \"paco21\"}),\n",
    "        W.rename(columns={\"ph1\": \"ph1\", \"hema1\": \"hema1\"}),\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "analysis_df = analysis_cols.dropna().copy()\n",
    "\n",
    "# Overwrite with cleaned arrays\n",
    "Y = analysis_df[\"Y\"].values\n",
    "A = analysis_df[\"A\"].values.astype(int)\n",
    "X_colnames = [col for col in analysis_df.columns if col not in [\"Y\", \"A\", \"pafi1\", \"paco21\", \"ph1\", \"hema1\"]]\n",
    "X = analysis_df[X_colnames]\n",
    "Z = analysis_df[[\"pafi1\", \"paco21\"]]\n",
    "W = analysis_df[[\"ph1\", \"hema1\"]]\n",
    "\n",
    "print(f\"\\nFinal X shape: {X.shape}\")\n",
    "analysis_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77d3a67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 4014\n",
      "Test samples: 1721\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, A_train, A_test, Y_train, Y_test, Z_train, Z_test, W_train, W_test = train_test_split(\n",
    "    X.values, A, Y, Z.values, W.values, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe7164a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Baseline predictions - Mean: -1.2749, Std: 1.3376\n",
      "Baseline predictions - Min: -5.9866, Max: 3.0967\n"
     ]
    }
   ],
   "source": [
    "baseline = BaselineCausalForestDML(n_estimators=200, min_samples_leaf=20, random_state=42)\n",
    "baseline.fit_baseline(X_train, A_train, Y_train, verbose=True)\n",
    "pred_baseline = baseline.effect(X_test).ravel()\n",
    "\n",
    "print(f\"\\nBaseline predictions - Mean: {pred_baseline.mean():.4f}, Std: {pred_baseline.std():.4f}\")\n",
    "print(f\"Baseline predictions - Min: {pred_baseline.min():.4f}, Max: {pred_baseline.max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3909902b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NC-CSF predictions - Mean: -1.1017, Std: 1.3517\n",
      "NC-CSF predictions - Min: -5.7010, Max: 3.0812\n"
     ]
    }
   ],
   "source": [
    "nccsf = NCCausalForestDML(n_estimators=200, min_samples_leaf=20, cv=5, random_state=42)\n",
    "nccsf.fit(Y=Y_train, T=A_train, X=X_train, Z=Z_train, W=W_train)\n",
    "pred_nccsf = nccsf.effect(X_test).ravel()\n",
    "\n",
    "print(f\"\\nNC-CSF predictions - Mean: {pred_nccsf.mean():.4f}, Std: {pred_nccsf.std():.4f}\")\n",
    "print(f\"NC-CSF predictions - Min: {pred_nccsf.min():.4f}, Max: {pred_nccsf.max():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0616d477",
   "metadata": {},
   "source": [
    "### Generate semi-syn (use real X, A, Z, W)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16d316e",
   "metadata": {},
   "source": [
    "**Severity Score Construction for Unmeasured Confounder $U$**\n",
    "\n",
    "We construct $U$ as a latent severity score from physiological lab values following a Gaussian factor model:\n",
    "\n",
    "1. **Standardize lab values**: For each lab measurement $L_j$ (where $j \\in \\{\\text{sod1, pot1, crea1, bili1, alb1, pafi1, paco21, ph1, hema1}\\}$):\n",
    "   $$\\tilde{L}_j = \\frac{L_j - \\bar{L}_j}{s_j}$$\n",
    "\n",
    "2. **Construct weighted score**: Using PCA to obtain weights $w_j$ from the first principal component:\n",
    "   $$U_i = \\sum_{j} w_j \\tilde{L}_{ij} + \\epsilon_i, \\quad \\epsilon_i \\sim \\mathcal{N}(0, \\sigma_U^2)$$\n",
    "\n",
    "3. **Standardize**: Final $U$ is standardized to have mean 0 and variance 1.\n",
    "\n",
    "This creates a realistic unmeasured confounder that represents underlying patient severity, influencing both treatment assignment and outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5d395586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size: 5735\n",
      "Severity score (U) - Mean: 0.0000, Std: 1.0000\n",
      "Target censoring rate: 0.00%\n",
      "Actual censoring rate: 0.05%\n",
      "Treatment proportion: 38.08%\n",
      "Mean CATE: 6165861685760.2764\n",
      "\n",
      "Observed data shape: (5735, 14)\n",
      "Columns: ['A', 'age', 'sex', 'cat1_coma', 'cat2_coma', 'dnr1', 'surv2md1', 'aps1', 'pafi1', 'paco21', 'ph1', 'hema1', 'time', 'event']\n",
      "\n",
      "Truth data shape: (5735, 25)\n",
      "Columns: ['U', 'A', 'age', 'sex', 'cat1_coma', 'cat2_coma', 'dnr1', 'surv2md1', 'aps1', 'pafi1', 'paco21', 'ph1', 'hema1', 'time', 'event', 'T0', 'T1', 'C0', 'C1', 'T', 'C', 'eta_t0', 'eta_t1', 'CATE_XU', 'ITE']\n",
      "\n",
      "First few rows of observed data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cat1_coma</th>\n",
       "      <th>cat2_coma</th>\n",
       "      <th>dnr1</th>\n",
       "      <th>surv2md1</th>\n",
       "      <th>aps1</th>\n",
       "      <th>pafi1</th>\n",
       "      <th>paco21</th>\n",
       "      <th>ph1</th>\n",
       "      <th>hema1</th>\n",
       "      <th>time</th>\n",
       "      <th>event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70.25098</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.640991</td>\n",
       "      <td>46</td>\n",
       "      <td>68.00000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>7.359375</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>1.996338e+08</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>78.17896</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.755000</td>\n",
       "      <td>50</td>\n",
       "      <td>218.31250</td>\n",
       "      <td>34.0</td>\n",
       "      <td>7.329102</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>1.030332e+10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>46.09198</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.317000</td>\n",
       "      <td>82</td>\n",
       "      <td>275.50000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.359375</td>\n",
       "      <td>21.097656</td>\n",
       "      <td>1.548373e-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>75.33197</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.440979</td>\n",
       "      <td>48</td>\n",
       "      <td>156.65625</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7.459961</td>\n",
       "      <td>26.296875</td>\n",
       "      <td>1.247323e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>67.90997</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.437000</td>\n",
       "      <td>72</td>\n",
       "      <td>478.00000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.229492</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>1.467039e+04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A       age  sex  cat1_coma  cat2_coma  dnr1  surv2md1  aps1      pafi1  \\\n",
       "0  0  70.25098    0          0          0     0  0.640991    46   68.00000   \n",
       "1  1  78.17896    1          0          0     0  0.755000    50  218.31250   \n",
       "2  1  46.09198    1          0          0     0  0.317000    82  275.50000   \n",
       "3  0  75.33197    1          0          0     0  0.440979    48  156.65625   \n",
       "4  1  67.90997    0          0          0     1  0.437000    72  478.00000   \n",
       "\n",
       "   paco21       ph1      hema1          time  event  \n",
       "0    40.0  7.359375  58.000000  1.996338e+08      1  \n",
       "1    34.0  7.329102  32.500000  1.030332e+10      1  \n",
       "2    16.0  7.359375  21.097656  1.548373e-01      1  \n",
       "3    30.0  7.459961  26.296875  1.247323e+09      1  \n",
       "4    17.0  7.229492  24.000000  1.467039e+04      1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def generate_semi_synthetic_data(\n",
    "    analysis_df,\n",
    "    original_df,\n",
    "    severity_columns=None,\n",
    "    use_pca=True,\n",
    "    sigma_u=0.3,\n",
    "    target_censor_rate=0.35,\n",
    "    k_t=1.5,\n",
    "    lam_t=0.4,\n",
    "    tau_log_hr=-0.6,\n",
    "    beta_u_in_t=0.8,\n",
    "    k_c=1.2,\n",
    "    beta_u_in_c=0.3,\n",
    "    seed=123\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate semi-synthetic survival data using real X, A, Z, W and synthetic Y.\n",
    "    U is constructed as a severity score from physiological variables (unmeasured confounder).\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    analysis_df : pd.DataFrame\n",
    "        DataFrame containing real X, A, Z, W columns (after dropna)\n",
    "    original_df : pd.DataFrame\n",
    "        Original DataFrame before dropna (for accessing severity columns)\n",
    "    severity_columns : list\n",
    "        List of column names to use for severity score U\n",
    "        Default: ['sod1', 'pot1', 'crea1', 'bili1', 'alb1', 'pafi1', 'paco21', 'ph1', 'hema1']\n",
    "    use_pca : bool\n",
    "        If True, use first principal component for weights; if False, use equal weights\n",
    "    sigma_u : float\n",
    "        Standard deviation of noise added to severity score (default: 0.3)\n",
    "   \n",
    "    Returns:\n",
    "    --------\n",
    "    observed_df : pd.DataFrame\n",
    "        DataFrame with semi-synthetic observed data (real X,A,Z,W and synthetic time, event)\n",
    "    truth_df : pd.DataFrame\n",
    "        DataFrame with additional ground truth columns (U, T0, T1, C0, C1, CATE, etc.)\n",
    "    \"\"\"\n",
    "    \n",
    "    if severity_columns is None:\n",
    "        severity_columns = ['sod1', 'pot1', 'crea1', 'bili1', 'alb1', 'pafi1', 'paco21', 'ph1', 'hema1']\n",
    "    \n",
    "    rng = np.random.default_rng(seed)\n",
    "    n = len(analysis_df)\n",
    "    \n",
    "    # Extract real data from analysis_df\n",
    "    A = analysis_df[\"A\"].values.astype(int)\n",
    "    X_colnames = [col for col in analysis_df.columns if col not in [\"Y\", \"A\", \"pafi1\", \"paco21\", \"ph1\", \"hema1\"]]\n",
    "    X = analysis_df[X_colnames].values\n",
    "    Z = analysis_df[[\"pafi1\", \"paco21\"]].values\n",
    "    W = analysis_df[[\"ph1\", \"hema1\"]].values\n",
    "    \n",
    "    p = X.shape[1]\n",
    "    \n",
    "    # Get indices of analysis_df in original_df to match rows\n",
    "    # We need to align the rows properly\n",
    "    analysis_indices = analysis_df.index\n",
    "    \n",
    "    # Extract severity columns from original_df using the same indices\n",
    "    severity_data = original_df.loc[analysis_indices, severity_columns].copy()\n",
    "    \n",
    "    # Handle missing values in severity columns (if any remain)\n",
    "    severity_data = severity_data.fillna(severity_data.mean())\n",
    "    \n",
    "    # Standardize the lab values: L_tilde = (L - mean(L)) / std(L)\n",
    "    scaler = StandardScaler()\n",
    "    L_tilde = scaler.fit_transform(severity_data)\n",
    "    \n",
    "    # Create severity score U (unmeasured confounder)\n",
    "    if use_pca:\n",
    "        # Use first principal component direction as weights\n",
    "        pca = PCA(n_components=1, random_state=seed)\n",
    "        U_score = pca.fit_transform(L_tilde).ravel()\n",
    "    else:\n",
    "        # Use equal weights\n",
    "        U_score = L_tilde.mean(axis=1)\n",
    "    \n",
    "    # Add Gaussian noise: U = weighted_sum + epsilon, epsilon ~ N(0, sigma_u^2)\n",
    "    epsilon = rng.normal(scale=sigma_u, size=n)\n",
    "    U = U_score + epsilon\n",
    "    \n",
    "    # Standardize U to have mean 0 and std 1 for consistency\n",
    "    U = (U - U.mean()) / U.std()\n",
    "    \n",
    "    # Helper functions from data_generation.py\n",
    "    def weibull_ph_time(u01, k, lam, eta):\n",
    "        u01 = np.clip(u01, 1e-12, 1 - 1e-12)\n",
    "        scale = lam * np.exp(-eta / k)\n",
    "        return scale * (-np.log(u01)) ** (1.0 / k)\n",
    "    \n",
    "    # Generate coefficients for outcome model\n",
    "    beta_t = rng.normal(scale=0.4, size=p)\n",
    "    \n",
    "    # Generate potential event times T0, T1\n",
    "    u_t = rng.random(n)\n",
    "    \n",
    "    # Linear predictor for event times\n",
    "    eta_t0 = X @ beta_t + beta_u_in_t * U + tau_log_hr * 0.0\n",
    "    eta_t1 = X @ beta_t + beta_u_in_t * U + tau_log_hr * 1.0\n",
    "    \n",
    "    T0 = weibull_ph_time(u_t, k=k_t, lam=lam_t, eta=eta_t0)\n",
    "    T1 = weibull_ph_time(u_t, k=k_t, lam=lam_t, eta=eta_t1)\n",
    "    \n",
    "    # Generate censoring times with calibration\n",
    "    beta_c = rng.normal(scale=0.3, size=p)\n",
    "    u_c = rng.random(n)\n",
    "    eta_c = X @ beta_c + beta_u_in_c * U\n",
    "    \n",
    "    # Calibrate censoring to achieve target censoring rate\n",
    "    T_obs_for_calib = np.where(A == 1, T1, T0)\n",
    "    \n",
    "    lo, hi = 1e-8, 1e6\n",
    "    for _ in range(60):\n",
    "        mid = 0.5 * (lo + hi)\n",
    "        C_mid = weibull_ph_time(u_c, k=k_c, lam=mid, eta=eta_c)\n",
    "        censor_rate_mid = (C_mid < T_obs_for_calib).mean()\n",
    "        if censor_rate_mid < target_censor_rate:\n",
    "            hi = mid\n",
    "        else:\n",
    "            lo = mid\n",
    "    lam_c_used = 0.5 * (lo + hi)\n",
    "    \n",
    "    C0 = weibull_ph_time(u_c, k=k_c, lam=lam_c_used, eta=eta_c)\n",
    "    C1 = weibull_ph_time(u_c, k=k_c, lam=lam_c_used, eta=eta_c)\n",
    "    \n",
    "    # Realized T, C and observed (time, event)\n",
    "    T = np.where(A == 1, T1, T0)\n",
    "    C = np.where(A == 1, C1, C0)\n",
    "    \n",
    "    time = np.minimum(T, C)\n",
    "    event = (T <= C).astype(int)\n",
    "    \n",
    "    # Create observed DataFrame (U is NOT included as it's unmeasured)\n",
    "    observed_df = analysis_df.copy()\n",
    "    observed_df[\"time\"] = time\n",
    "    observed_df[\"event\"] = event\n",
    "    \n",
    "    # Drop original Y if it exists, replace with new outcome\n",
    "    if \"Y\" in observed_df.columns:\n",
    "        observed_df = observed_df.drop(columns=[\"Y\"])\n",
    "    \n",
    "    # Create truth DataFrame with additional ground truth information (including U)\n",
    "    truth_df = observed_df.copy()\n",
    "    truth_df.insert(0, \"U\", U)\n",
    "    truth_df[\"T0\"] = T0\n",
    "    truth_df[\"T1\"] = T1\n",
    "    truth_df[\"C0\"] = C0\n",
    "    truth_df[\"C1\"] = C1\n",
    "    truth_df[\"T\"] = T\n",
    "    truth_df[\"C\"] = C\n",
    "    truth_df[\"eta_t0\"] = eta_t0\n",
    "    truth_df[\"eta_t1\"] = eta_t1\n",
    "    \n",
    "    # Add ground truth CATE\n",
    "    # For Weibull PH model: E[T | η] = λ * Γ(1 + 1/k) * exp(-η/k)\n",
    "    # CATE = E[T(1) - T(0) | X,U] = λ * Γ(1 + 1/k) * (exp(-η₁/k) - exp(-η₀/k))\n",
    "    G = math.gamma(1.0 + 1.0 / k_t)\n",
    "    cate_xu = lam_t * G * (np.exp(-eta_t1 / k_t) - np.exp(-eta_t0 / k_t))\n",
    "    truth_df[\"CATE_XU\"] = cate_xu\n",
    "    truth_df[\"ITE\"] = T1 - T0\n",
    "    \n",
    "    actual_censor_rate = (event == 0).mean()\n",
    "    print(f\"Sample size: {n}\")\n",
    "    print(f\"Severity score (U) - Mean: {U.mean():.4f}, Std: {U.std():.4f}\")\n",
    "    print(f\"Target censoring rate: {target_censor_rate:.2%}\")\n",
    "    print(f\"Actual censoring rate: {actual_censor_rate:.2%}\")\n",
    "    print(f\"Treatment proportion: {A.mean():.2%}\")\n",
    "    print(f\"Mean CATE: {cate_xu.mean():.4f}\")\n",
    "    \n",
    "    return observed_df, truth_df\n",
    "\n",
    "# Generate semi-synthetic dataset with severity score U\n",
    "observed_df, truth_df = generate_semi_synthetic_data(\n",
    "    analysis_df=analysis_df,\n",
    "    original_df=df,\n",
    "    severity_columns=['sod1', 'pot1', 'crea1', 'bili1', 'alb1', 'pafi1', 'paco21', 'ph1', 'hema1'],\n",
    "    use_pca=True,\n",
    "    sigma_u=0.3,\n",
    "    target_censor_rate=0,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(\"\\nObserved data shape:\", observed_df.shape)\n",
    "print(\"Columns:\", list(observed_df.columns))\n",
    "print(\"\\nTruth data shape:\", truth_df.shape)\n",
    "print(\"Columns:\", list(truth_df.columns))\n",
    "print(\"\\nFirst few rows of observed data:\")\n",
    "observed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d8892b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
